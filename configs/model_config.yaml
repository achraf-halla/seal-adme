# SEAL-ADME Model Configuration

# Data paths
data:
  graph_dir: data/graphs
  split_dir: data/splits
  
# Model architecture
model:
  encoder_type: gcn  # gcn or gin
  input_features: 25
  hidden_features: 256
  num_layers: 4
  dropout: 0.1
  regularize_encoder: 1.0e-4
  regularize_contribution: 0.5
  train_eps: false  # Only for GIN

# Pretraining configuration (classification)
pretrain:
  epochs: 50
  batch_size: 64
  lr: 1.0e-3
  weight_decay: 1.0e-5
  samples_per_task: 500  # null for balanced
  grad_clip: 1.0
  lr_patience: 5
  early_stop_patience: 15

# Finetuning configuration (regression)
finetune:
  task_names:
    - solubility_aqsoldb
    - caco2_wang
    - half_life_obach
  epochs: 150
  batch_size: 64
  lr: 3.0e-4
  weight_decay: 1.0e-6
  mse_weight: 1.0
  grad_clip: 1.0
  lr_patience: 8
  early_stop_patience: 25
  task_sampling: proportional  # proportional or round_robin
  freeze_encoder: false
  validate_batch_size: 128

# Inference configuration
inference:
  batch_size: 8
  splits:
    - test
  visualize: true
  vis_samples: 10
